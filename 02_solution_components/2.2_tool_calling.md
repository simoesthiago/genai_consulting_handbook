# TOOL CALLING (Function Calling)

**Goal:** Enable LLMs to interact with external systems and APIs, performing actions beyond text generation—from checking order status to processing refunds—while maintaining security, reliability, and observability.

**Prerequisites:**
- [`../01-foundations/1.1_llm_fundamentals.md`](../01-foundations/1.1_llm_fundamentals.md) — Understanding LLM capabilities and limitations
- [`../01-foundations/1.2_prompt_engineering.md`](../01-foundations/1.2_prompt_engineering.md) — How to structure prompts
- [`2.1_rag.md`](./2.1_rag.md) — Understanding RAG (often combined with tool calling)

**Related:**
- [`agentic_ai.md`](./agentic_ai.md) — Tool calling in agentic systems
- [`guardrails.md`](./guardrails.md) — Security controls for tool calls
- [`evals.md`](./evals.md) — Measuring tool calling quality
- [`observability_llmops.md`](./observability_llmops.md) — Observing tool calls

---

## TL;DR (30 seconds)

- **Tool calling enables LLMs to perform actions** (check order status, process refunds, update databases) beyond just answering questions
- **Requires schemas** (JSON Schema format) that define what tools are available and how to use them
- **Critical for security**: Use allowlists (only allow specific tools), audit all calls, prevent "confused deputy" attacks
- **Reliability patterns**: Retries with exponential backoff, rate limiting, circuit breakers for external services
- **Idempotency matters**: Ensure calling the same action twice has the same effect as calling it once
- **Observability is essential**: Track tool name, parameters, execution time, success/failure for debugging and compliance

---

## What's In / What's Out

**In:**
- Tool calling architecture and end-to-end flow
- Contract design (schemas, validation, idempotency)
- Reliability patterns (retries, backoff, rate limiting, circuit breakers)
- Security patterns (allowlists, auditing, "confused deputy" prevention)
- Observability requirements (what to track, how to trace)
- Trade-offs and decision frameworks
- Comprehensive case study with rationale

**Out:**
- Specific LLM provider implementation details (OpenAI vs Anthropic vs open-source)
- Detailed prompt engineering for tool selection (covered in [`prompt_engineering.md`](../01-foundations/1.2_prompt_engineering.md))
- Multi-agent coordination (covered in [`multi_agent_systems.md`](./multi_agent_systems.md))
- Advanced agentic patterns (covered in [`agentic_ai.md`](./agentic_ai.md))

---

## 1. WHAT IS TOOL CALLING / WHEN TO USE / WHEN TO AVOID

### 1.1. What is Tool Calling?

**Definition:** Tool calling (also called function calling) is a mechanism that allows LLMs to request execution of external functions or APIs. The LLM receives a list of available tools (with schemas describing their parameters), decides which tool to call based on the user's request, and the system executes the tool and returns results to the LLM. Tool calling is like giving an AI assistant a toolbox with specific tools it can use. Instead of just answering questions, the AI can now perform actions: use a calculator, check a calendar, send an email, or query a database. Each tool has clear instructions (a "schema") that tell the AI when and how to use it.

**Key insight:** Tool calling bridges the gap between LLM knowledge (what it learned during training) and real-world actions (what it can do right now). An LLM can't directly check your order database, but with tool calling, it can call a function that does.

### 1.2. When to Use Tool Calling

**Use tool calling when you are building and agentic system, that is, AI that makes decisions and takes actions autonomously**

- **You need to perform actions:** User requests require doing something, not just answering
  - Example: "Process a refund for order #12345" → Requires calling `process_refund(order_id, amount)`

- **You need real-time data:** Information changes frequently and must be current
  - Example: "What's the current inventory for product X?" → Requires calling `check_inventory(product_id)` (not RAG, because inventory changes in real-time)

- **You need to interact with external systems:** Databases, APIs, services, or internal tools
  - Example: Customer support bot that checks CRM, updates tickets, sends emails
  - Example: Internal assistant that queries data warehouse, creates JIRA tickets, updates Slack

### 1.3. Tool Calling vs RAG: When to Use Each

**RAG (Retrieval-Augmented Generation):**
- **Purpose:** Retrieve knowledge from documents/knowledge base
- **Use when:** User needs information ("What is X?", "How does Y work?")
- **Example:** "What is our vacation policy?" → RAG retrieves policy document, LLM answers

**Tool Calling:**
- **Purpose:** Perform actions or get real-time data
- **Use when:** User needs to do something or get current state ("Check X", "Update Y", "Process Z")
- **Example:** "Check my order status" → Tool calling executes `get_order_status(order_id)`

**Both Together (Common Pattern):**
- **Example:** "What's our refund policy and process a refund for order #123"
  - Step 1: RAG retrieves refund policy (knowledge)
  - Step 2: Tool calling executes `process_refund(order_id)` (action)

---

## 2. TOOL CALLING ARCHITECTURE

```
┌──────────────┐
│  User Query  │
│ "Check order │
│  #123 status"│
└──────┬───────┘
       │
       ▼
┌─────────────────────────────────────┐
│         LLM (with Tool List)        │
│  - Receives available tools          │
│  - Decides which tool to call        │
│  - Generates tool call request       │
└──────┬───────────────────────────────┘
       │
       │ Tool Call Request
       │ {tool: "get_order_status",
       │  parameters: {order_id: "123"}}
       │
       ▼
┌─────────────────────────────────────┐
│      Tool Selection & Validation      │
│  - Check allowlist (is tool allowed?) │
│  - Validate parameters (schema check) │
│  - Check user permissions             │
└──────┬───────────────────────────────┘
       │
       │ Validated Request
       │
       ▼
┌─────────────────────────────────────┐
│        Tool Execution                │
│  - Execute tool (API call, DB query) │
│  - Handle errors (retry if needed)   │
│  - Return result                     │
└──────┬───────────────────────────────┘
       │
       │ Tool Result
       │ {status: "shipped",
       │  tracking: "ABC123"}
       │
       ▼
┌─────────────────────────────────────┐
│         LLM (with Result)            │
│  - Receives tool result              │
│  - Generates user-friendly response  │
└──────┬───────────────────────────────┘
       │
       ▼
┌──────────────┐
│ User Response │
│ "Your order  │
│ is shipped..."│
└──────────────┘
```

### 2.1. End-to-End Flow (Detailed)

**Step 1: User Query**
- User: "Check the status of order #12345 and process a refund if it's not shipped"

**Step 2: LLM Receives Tool List**
- System sends LLM:
  - Available tools: `get_order_status`, `process_refund`, `check_inventory`
  - Tool schemas (what each tool does, what parameters it needs)
  - User query

**Step 3: LLM Decides to Call Tool**
- LLM analyzes query and decides: "I need to call `get_order_status` first"
- LLM generates tool call: `{tool: "get_order_status", parameters: {order_id: "12345"}}`

**Step 4: Validation**
- System checks: Is `get_order_status` in the allowlist? ✅ Yes
- System checks: Does user have permission to check orders? ✅ Yes
- System validates: Does `order_id` match schema (string, required)? ✅ Yes

**Step 5: Tool Execution**
- System calls: `get_order_status(order_id="12345")`
- External service returns: `{status: "pending", shipped: false}`

**Step 6: LLM Receives Result**
- LLM sees: Order is not shipped
- LLM decides: User asked to process refund if not shipped, so I should call `process_refund`
- LLM generates second tool call: `{tool: "process_refund", parameters: {order_id: "12345"}}`

**Step 7: Second Tool Call (Same Validation + Execution)**
- Validation ✅
- Execution: `process_refund(order_id="12345")` → Returns `{refund_id: "REF789", status: "processed"}`

**Step 8: Final Response**
- LLM generates: "I checked order #12345 and it hasn't been shipped yet. I've processed a refund (Refund ID: REF789). You should receive the refund in 3-5 business days."

**Step 9: Audit Logging**
- System logs: User ID, tools called, parameters (sanitized), results, timestamp

---

## 3. CONTRACTS: SCHEMAS, VALIDATION, IDEMPOTENCY

### 3.1. Tool Schemas (JSON Schema Format)

**What is a tool schema?** A schema is like a "recipe card" for each tool. It tells the LLM:
- What the tool does (description)
- What parameters it needs (name, type, required/optional)
- What each parameter means (description)

**Why schemas matter:**
- **LLM needs clear instructions:** Without a schema, the LLM doesn't know what tools are available or how to use them
- **Validation:** Schemas enable automatic validation (catch errors before execution)
- **Documentation:** Schemas serve as documentation for developers and the LLM

**Example: Well-Designed Tool Schema**

```json
{
  "name": "get_order_status",
  "description": "Retrieves the current status of an order. Use this when the user asks about order status, shipping information, or delivery dates.",
  "parameters": {
    "type": "object",
    "properties": {
      "order_id": {
        "type": "string",
        "description": "The unique order identifier (e.g., 'ORD-12345'). Always required.",
        "pattern": "^ORD-[0-9]{5}$"
      },
      "include_tracking": {
        "type": "boolean",
        "description": "Whether to include tracking information. Defaults to false.",
        "default": false
      }
    },
    "required": ["order_id"]
  }
}
```

**What makes this schema good:**
- **Clear description:** Tells LLM when to use this tool
- **Parameter descriptions:** Each parameter explains what it is and when to use it
- **Type validation:** `order_id` is a string, `include_tracking` is a boolean
- **Pattern validation:** `order_id` must match format `ORD-XXXXX`
- **Required fields:** Clearly marked (`order_id` is required)
- **Defaults:** `include_tracking` has a default value

### 3.2. Validation: Why It Matters

**What is validation?** Validation checks that tool call parameters match the schema before execution.

**Why validation is critical:**

1. **Prevent errors:** Catch invalid parameters before calling external services
   - Example: `order_id` must be `ORD-XXXXX` format. If user says "order 123", validation catches it before API call fails
2. **Security:** Prevent injection attacks or malicious parameters
   - Example: If `order_id` should be a string, reject if it's an object with malicious code
3. **Cost savings:** Failed API calls waste money and time. Validation catches errors early
4. **Better user experience:** Return clear error messages ("Invalid order ID format") instead of cryptic API errors

**Validation layers:**

1. **Schema validation:** Check types, required fields, patterns
   ```python
   # Pseudocode
   if not schema.validate(tool_call.parameters):
       return error("Invalid parameters: order_id must match pattern ORD-XXXXX")
   ```
2. **Business logic validation:** Check if values make sense
   ```python
   # Pseudocode
   if order_id not in user_orders:
       return error("You don't have access to this order")
   ```
3. **Permission validation:** Check if user can call this tool with these parameters
   ```python
   # Pseudocode
   if not user.can_access_order(order_id):
       return error("Access denied")
   ```

### 3.3. Idempotency: Why It Matters and How to Implement

**What is idempotency?** An idempotent operation is one that can be called multiple times with the same result. Calling it once has the same effect as calling it twice.

**Simple analogy:** 
- **Idempotent:** "Get the current time" → Same result every time you call it
- **Not idempotent:** "Create a new order" → Each call creates a different order

**Why idempotency matters:**

1. **Retry safety:** If a tool call fails and you retry, you don't want duplicate actions
   - Example: User says "process refund" → Tool call fails → Retry → Without idempotency, refund might be processed twice
2. **Network reliability:** Network issues can cause duplicate requests
   - Example: Request sent, no response received → Retry → Original request actually succeeded → Now you have two requests
3. **User experience:** Users might click "submit" twice or ask the same question twice

**How to make tools idempotent:**

**Strategy 1: Idempotency Keys**
- Each tool call gets a unique idempotency key (UUID)
- System stores: "I already processed request with key ABC123"
- If same key is used again, return the previous result (don't execute again)

```python
# Pseudocode
def process_refund(order_id, amount, idempotency_key):
    if already_processed(idempotency_key):
        return get_previous_result(idempotency_key)
    
    result = execute_refund(order_id, amount)
    store_result(idempotency_key, result)
    return result
```

**Strategy 2: Check-Before-Act**
- Before performing an action, check if it's already done
- Example: Before creating order, check if order with same parameters already exists

```python
# Pseudocode
def create_order(customer_id, items):
    existing_order = find_order(customer_id, items, status="pending")
    if existing_order:
        return existing_order  # Already exists, return it
    
    return create_new_order(customer_id, items)
```

**Strategy 3: Natural Idempotency**
- Some operations are naturally idempotent
- Example: `update_account_email(user_id, new_email)` → Setting email to the same value twice has the same effect

**Which tools should be idempotent?**

- **Must be idempotent:** Actions that change state (refunds, updates, creates with checks)
- **Naturally idempotent:** Read operations (get order status, check inventory)
- **Can't be idempotent:** Some operations are inherently one-time (e.g., "send email" - you can't unsend)

**Example: Idempotent Refund Tool**

```json
{
  "name": "process_refund",
  "description": "Processes a refund for an order. Idempotent: calling with the same idempotency_key returns the same result.",
  "parameters": {
    "type": "object",
    "properties": {
      "order_id": {
        "type": "string",
        "description": "The order ID to refund"
      },
      "amount": {
        "type": "number",
        "description": "Refund amount (must be <= order total)"
      },
      "idempotency_key": {
        "type": "string",
        "description": "Unique key to ensure idempotency. If same key is used, returns previous result."
      }
    },
    "required": ["order_id", "amount", "idempotency_key"]
  }
}
```

---

## 4. RELIABILITY PATTERNS

Tool calling involves external systems (APIs, databases, services) that can fail. Reliability patterns ensure your system handles failures gracefully.

### 4.1. Retries and Backoff Strategies

**The problem:** External services can fail temporarily (network issues, service overload, transient errors). You don't want to give up after the first failure.

**Solution: Retry with exponential backoff**

**What is exponential backoff?** Wait longer between each retry attempt:
- Attempt 1: Immediate
- Attempt 2: Wait 1 second
- Attempt 3: Wait 2 seconds
- Attempt 4: Wait 4 seconds
- Attempt 5: Wait 8 seconds

**Why exponential?** Gives the service time to recover. If it's overloaded, waiting longer helps.

**Implementation example:**

```python
# Pseudocode
def execute_tool_with_retry(tool_call, max_retries=3):
    for attempt in range(max_retries):
        try:
            result = execute_tool(tool_call)
            return result
        except TransientError as e:
            if attempt == max_retries - 1:
                raise  # Last attempt failed
            wait_time = 2 ** attempt  # Exponential backoff: 1s, 2s, 4s
            sleep(wait_time)
        except PermanentError as e:
            return error("Cannot retry: " + str(e))  # Don't retry permanent errors
```

**When to retry:**
- **Transient errors:** Network timeouts, 5xx HTTP errors, service temporarily unavailable
- **Rate limit errors:** 429 Too Many Requests (wait and retry)

**When NOT to retry:**
- **Permanent errors:** 404 Not Found, 400 Bad Request (invalid parameters)
- **Authentication errors:** 401 Unauthorized (retrying won't help)
- **Idempotent operations:** If already succeeded, don't retry (use idempotency key)

**Max retries decision:**
- **MVP:** 2-3 retries (simple, fast to implement)
- **Production:** 3-5 retries with jitter (random delay to prevent thundering herd)

### 4.2. Rate Limiting

**The problem:** External APIs have rate limits (e.g., "100 requests per minute"). If you exceed the limit, requests fail. You need to control how fast you call tools.

**What is rate limiting?** Rate limiting controls how many tool calls you make per time period (e.g., "max 10 calls per second to this API").

**Why it matters:**
- **Prevent API failures:** Stay within external service limits
- **Cost control:** Some APIs charge per request; rate limiting prevents runaway costs
- **Fair usage:** Don't overwhelm external services

**Implementation strategies:**

**1. Per-tool rate limiting:**
- Each tool has its own rate limit
- Example: `get_order_status` → 100 calls/minute, `process_refund` → 10 calls/minute

**2. Token bucket algorithm:**
- Bucket has tokens (e.g., 100 tokens)
- Each tool call consumes 1 token
- Tokens refill over time (e.g., 1 token per second)
- If bucket is empty, wait until token is available

**3. Sliding window:**
- Track calls in the last N seconds
- If limit exceeded, wait until oldest call expires

**Example: Rate limiting for refund tool**

```python
# Pseudocode
rate_limiter = RateLimiter(tool="process_refund", max_calls=10, window_seconds=60)

def execute_refund(order_id):
    rate_limiter.wait_if_needed()  # Wait if at limit
    return process_refund(order_id)
```

### 4.3. Circuit Breakers

**The problem:** If an external service is down, you don't want to keep trying (wasting time and resources). You want to "fail fast" and stop calling it temporarily.

**What is a circuit breaker?** A circuit breaker monitors failures. If failures exceed a threshold, it "opens" (stops calling the service) for a period. After the period, it "closes" (tries again).

**Simple analogy:** Like a home circuit breaker—if too much current flows, it trips and stops electricity. You reset it after checking the problem.

**Circuit breaker states:**

1. **Closed (normal):** Tool calls go through normally
2. **Open (failing):** Service is failing, don't call it (return error immediately)
3. **Half-open (testing):** Service might be back, try one call to test

**When to use circuit breakers:**
- **External APIs:** Services you don't control (third-party APIs)
- **Critical tools:** Tools that, if they fail, cause cascading failures
- **High-volume systems:** Where many failures waste resources

**Implementation example:**

```python
# Pseudocode
circuit_breaker = CircuitBreaker(
    failure_threshold=5,  # Open after 5 failures
    timeout_seconds=60,   # Stay open for 60 seconds
    half_open_timeout=10  # Try again after 10 seconds
)

def execute_tool_with_circuit_breaker(tool_call):
    if circuit_breaker.is_open():
        return error("Service temporarily unavailable")
    
    try:
        result = execute_tool(tool_call)
        circuit_breaker.record_success()
        return result
    except Exception as e:
        circuit_breaker.record_failure()
        raise
```

**Decision: When to open circuit breaker?**
- **Failure threshold:** Open after N consecutive failures (e.g., 5 failures)
- **Timeout:** How long to stay open (e.g., 60 seconds)
- **Half-open testing:** Try one call after timeout to see if service recovered

### 4.4. Error Handling and Graceful Degradation

**The problem:** Tool calls can fail for many reasons. You need to handle errors gracefully without breaking the user experience.

**Error types:**

1. **Transient errors:** Temporary failures (network timeout, service overload)
   - **Action:** Retry with backoff
   - **User message:** "Service is temporarily unavailable, please try again"

2. **Permanent errors:** Invalid request, not found, permission denied
   - **Action:** Don't retry, return error to user
   - **User message:** "Order #123 not found" or "You don't have permission"

3. **Partial failures:** Some tools succeed, others fail
   - **Action:** Return partial results, explain what failed
   - **User message:** "I checked your order status (shipped), but couldn't process the refund (service error). Please try again later."

**Graceful degradation strategies:**

**1. Fallback responses:**
- If tool fails, LLM can still answer based on available information
- Example: "I couldn't check your order status right now, but based on your previous orders, typical shipping time is 3-5 days."

**2. Cached results:**
- If tool fails, return cached result (if available and not too stale)
- Example: Order status cached from 5 minutes ago (acceptable for user)

**3. Alternative tools:**
- If primary tool fails, try alternative
- Example: If `get_order_status` fails, try `get_order_from_database`

**4. Human escalation:**
- If critical tool fails, escalate to human
- Example: Refund processing fails → "I couldn't process your refund automatically. A support agent will contact you within 1 hour."

---

## 5. SECURITY: ALLOWLIST, AUDITING, "CONFUSED DEPUTY"

Tool calling is powerful but dangerous if not secured. This section covers essential security patterns.

### 5.1. Allowlist Approach (Only Allow Specific Tools)

**The problem:** If you let the LLM call any tool dynamically, it might call tools it shouldn't (e.g., delete all orders, access admin functions).

**Solution: Allowlist (whitelist)**

**What is an allowlist?** A list of tools that are explicitly allowed. The LLM can only call tools on this list. Everything else is rejected.

**Why allowlist (not blocklist):**
- **Blocklist problem:** You have to list everything that's forbidden (impossible to be complete)
- **Allowlist advantage:** You explicitly list what's allowed (safer, clearer)

**Implementation:**

```python
# Pseudocode
ALLOWED_TOOLS = [
    "get_order_status",
    "check_inventory",
    "process_refund",  # Only if user has permission
    # "delete_order",  # NOT in allowlist = forbidden
]

def validate_tool_call(tool_call):
    if tool_call.tool_name not in ALLOWED_TOOLS:
        return error("Tool not allowed: " + tool_call.tool_name)
    return validated
```

**Decision: What tools to allow?**
- **Principle of least privilege:** Only allow tools needed for the use case
- **Review process:** New tools require security review before adding to allowlist
- **User-specific allowlists:** Different users might have different allowed tools
  - Example: Customer support agents can call `process_refund`, regular users cannot

### 5.2. Audit Logging (What to Log)

**The problem:** You need to know who called what tool, when, and what happened. This is critical for:
- **Compliance:** Regulated industries require audit trails
- **Security:** Detect unauthorized access or abuse
- **Debugging:** Understand what went wrong

**What to log (minimum):**
1. **User identity:** Who made the request (user_id, session_id)
2. **Tool name:** Which tool was called
3. **Parameters:** What parameters were passed (sanitized—remove sensitive data)
4. **Timestamp:** When it was called
5. **Result:** Success or failure, error message if failed
6. **Execution time:** How long it took (for performance monitoring)

**What NOT to log (security):**
- **Passwords, API keys, tokens:** Never log authentication secrets
- **Full PII:** Don't log full credit card numbers, SSNs (log last 4 digits only)
- **Sensitive business data:** Don't log proprietary information unnecessarily

**Example audit log entry:**

```json
{
  "timestamp": "2024-01-15T10:30:45Z",
  "user_id": "user_12345",
  "session_id": "sess_abc123",
  "tool_name": "process_refund",
  "parameters": {
    "order_id": "ORD-12345",
    "amount": 99.99
    // Note: idempotency_key not logged (internal)
  },
  "result": "success",
  "refund_id": "REF-789",
  "execution_time_ms": 245,
  "ip_address": "192.168.1.100"
}
```

**Sanitization example:**

```python
# Pseudocode
def sanitize_parameters(parameters):
    sanitized = parameters.copy()
    # Remove sensitive fields
    sanitized.pop("password", None)
    sanitized.pop("api_key", None)
    # Mask PII
    if "credit_card" in sanitized:
        sanitized["credit_card"] = mask_card(sanitized["credit_card"])  # "****1234"
    return sanitized
```

**Retention policy:**
- **How long to keep logs:** Depends on compliance requirements (e.g., 7 years for financial)
- **Where to store:** Secure, encrypted log storage (not in application database)
- **Access control:** Only authorized personnel can access audit logs

### 5.3. "Confused Deputy" Problem

**What is the "Confused Deputy" problem?** A security vulnerability where a system (the "deputy") is tricked into performing actions on behalf of a user who shouldn't have permission.

**Simple analogy:** Imagine a security guard (deputy) who checks if you have a key to a building. An attacker gives you a key, you show it to the guard, and the guard lets you in—even though you shouldn't be allowed. The guard is "confused" because it only checked the key, not whether you should have it.

**How it applies to tool calling:**

**Scenario:** User A doesn't have permission to process refunds, but User B does. User A tricks the system into processing a refund by:
1. User A asks LLM: "Process refund for order #123"
2. LLM calls `process_refund(order_id="123")`
3. System checks: "Is `process_refund` tool allowed?" ✅ Yes (it's in allowlist)
4. System executes refund
5. **Problem:** System didn't check if User A has permission to process refunds!

**The vulnerability:** The system validated the tool (is it allowed?) but not the user's permission (can this user call this tool?).

**How to prevent:**

**1. Validate user permissions, not just tool permissions:**

```python
# Pseudocode - WRONG (vulnerable to confused deputy)
def execute_tool(tool_call, user):
    if tool_call.tool_name in ALLOWED_TOOLS:  # Only checks tool
        return execute(tool_call)  # ❌ Doesn't check user permission

# Pseudocode - CORRECT (prevents confused deputy)
def execute_tool(tool_call, user):
    if tool_call.tool_name not in ALLOWED_TOOLS:
        return error("Tool not allowed")
    
    if not user.can_call_tool(tool_call.tool_name):  # ✅ Checks user permission
        return error("You don't have permission to call this tool")
    
    if not user.can_access_resource(tool_call.parameters):  # ✅ Checks resource access
        return error("You don't have access to this resource")
    
    return execute(tool_call)
```

**2. Validate resource-level permissions:**

Not just "can user call this tool?" but also "can user access this specific resource?"

```python
# Pseudocode
def process_refund(order_id, user):
    # Check: Can user call process_refund? ✅
    if not user.can_call_tool("process_refund"):
        return error("Permission denied")
    
    # Check: Can user access this specific order? ✅
    order = get_order(order_id)
    if order.user_id != user.id and not user.is_admin():
        return error("You don't have access to this order")
    
    return execute_refund(order_id)
```

**3. Use ABAC (Attribute-Based Access Control):**

Check user attributes (role, department, clearance level) against resource attributes:

```python
# Pseudocode
def can_process_refund(user, order):
    # User attributes
    user_role = user.role  # "customer_support", "admin", "customer"
    user_department = user.department  # "support", "finance"
    
    # Resource attributes
    order_amount = order.amount
    order_department = order.department  # Which department owns this order
    
    # Policy: Support can refund orders < $1000, Finance can refund any order
    if user_role == "customer_support" and order_amount < 1000:
        return True
    if user_department == "finance":
        return True
    
    return False
```

**Key principle:** Always validate both:
1. **Tool permission:** Is this tool allowed? (allowlist check)
2. **User permission:** Can this user call this tool? (user role/attributes)
3. **Resource permission:** Can this user access this specific resource? (resource ownership/attributes)

### 5.4. Input Validation and Sanitization

**The problem:** Tool parameters come from user input (via LLM). Malicious users might try to inject code, SQL, or other attacks.

**What to validate:**
1. **Type validation:** Parameter matches expected type (string, number, boolean)
2. **Format validation:** Matches expected pattern (e.g., order_id must be `ORD-XXXXX`)
3. **Range validation:** Numbers within expected range (e.g., refund amount > 0 and <= order total)
4. **Enum validation:** Value is one of allowed options (e.g., status must be "pending", "shipped", "delivered")

**What to sanitize:**
1. **SQL injection:** If tool calls database, sanitize SQL parameters
2. **Command injection:** If tool executes shell commands, sanitize inputs
3. **XSS (Cross-Site Scripting):** If tool returns HTML, sanitize output
4. **Path traversal:** If tool accesses files, validate file paths

**Example: Validation for refund tool**

```python
# Pseudocode
def validate_refund_parameters(order_id, amount, user):
    # Type validation
    if not isinstance(order_id, str):
        return error("order_id must be a string")
    if not isinstance(amount, (int, float)):
        return error("amount must be a number")
    
    # Format validation
    if not re.match(r"^ORD-[0-9]{5}$", order_id):
        return error("order_id must match format ORD-XXXXX")
    
    # Range validation
    if amount <= 0:
        return error("amount must be positive")
    
    order = get_order(order_id)
    if amount > order.total:
        return error("refund amount cannot exceed order total")
    
    # Permission validation
    if not user.can_access_order(order_id):
        return error("You don't have access to this order")
    
    return validated
```

**For detailed security patterns, see:** [`guardrails.md`](./guardrails.md)

---

## 6. OBSERVABILITY OF TOOL CALLS

Observability is critical for understanding what your system is doing, debugging issues, and meeting compliance requirements.

### 6.1. What to Instrument

**Minimum instrumentation (MVP):**
1. **Tool name:** Which tool was called
2. **Parameters (sanitized):** What parameters were passed (remove sensitive data)
3. **Execution time:** How long it took (latency)
4. **Success/failure:** Did it succeed or fail?
5. **Error message:** If it failed, what was the error?
6. **User ID:** Who made the request
7. **Timestamp:** When it was called

**Production instrumentation (additional):**
8. **Request ID:** Unique ID to trace end-to-end (connects tool call to user request)
9. **Retry count:** How many times it was retried
10. **Rate limit status:** Was it rate limited?
11. **Circuit breaker status:** Was circuit breaker open?
12. **Token usage:** If tool calls LLM internally, track tokens
13. **Cost:** Cost per tool call (for FinOps)

### 6.2. Tracing End-to-End

**The problem:** A user request might trigger multiple tool calls. You need to trace the entire flow to understand what happened.

**Solution: Request ID (correlation ID)**

**How it works:**
1. User makes request → Generate unique request ID (e.g., `req_abc123`)
2. All tool calls in this request use the same request ID
3. Logs, metrics, traces all include this request ID
4. You can search logs by request ID to see the full flow

**Example trace:**

```
Request ID: req_abc123
User: user_456
Query: "Check order #12345 and process refund if not shipped"

Timeline:
10:30:00.100 - User query received
10:30:00.150 - LLM decided to call get_order_status
10:30:00.200 - Tool call: get_order_status(order_id="ORD-12345")
10:30:00.445 - Tool result: {status: "pending", shipped: false}
10:30:00.500 - LLM decided to call process_refund
10:30:00.550 - Tool call: process_refund(order_id="ORD-12345", amount=99.99)
10:30:00.795 - Tool result: {refund_id: "REF-789", status: "processed"}
10:30:00.900 - Final response generated
10:30:00.950 - Response sent to user
```

**Benefits:**
- **Debugging:** If user reports issue, search by request ID to see full flow
- **Performance:** Identify bottlenecks (which tool call was slow?)
- **Compliance:** Full audit trail of what happened

### 6.3. Metrics to Track

**Key metrics for tool calling:**

1. **Tool call success rate:** % of tool calls that succeed
   - Target: >99% for critical tools, >95% for non-critical
   - Alert if: Success rate drops below threshold

2. **Tool call latency (P50, P95, P99):** How long tool calls take
   - P50 (median): Typical latency
   - P95: 95% of calls are faster than this
   - P99: 99% of calls are faster than this (catches outliers)
   - Alert if: P95 latency exceeds SLA (e.g., >2 seconds)

3. **Error rate by tool:** Which tools fail most often?
   - Helps identify problematic tools
   - Example: `process_refund` has 5% error rate → investigate

4. **Error rate by error type:** What types of errors occur?
   - Transient errors (retryable) vs permanent errors (not retryable)
   - Example: 80% of errors are rate limits → need better rate limiting

5. **Tool call volume:** How many calls per tool per time period?
   - Helps with capacity planning
   - Example: `get_order_status` called 10,000 times/day

6. **Cost per tool call:** Financial tracking
   - Example: `process_refund` costs $0.01 per call (API fees)

**Example dashboard:**

```
Tool Call Metrics (Last 24 hours)

Tool Name              | Calls | Success Rate | P95 Latency | Error Rate
-----------------------|-------|--------------|-------------|------------
get_order_status       | 10,234| 99.8%        | 245ms       | 0.2%
process_refund         | 1,234 | 98.5%        | 1.2s        | 1.5%
check_inventory        | 5,678 | 99.9%        | 180ms       | 0.1%
update_account         | 890   | 97.2%        | 890ms       | 2.8%
```

**For detailed observability patterns, see:** [`observability_llmops.md`](./observability_llmops.md)

---

## 7. CASE STUDY: CUSTOMER SUPPORT BOT WITH TOOL CALLING

This case study walks through a complete tool calling implementation, explaining the rationale behind each decision.

**Company:** E-CommerceCorp, online retailer  
**Problem:** Customer support team spends 40% of time on routine tasks (checking order status, processing refunds, updating accounts). Customers wait 15+ minutes for simple requests.  
**Goal:** Build an AI assistant that can handle routine support tasks autonomously, with human escalation for complex issues.  
**Constraints:** $2000/month budget, 8-week MVP timeline, >95% accuracy for order status checks, <5s response time, zero security incidents, full audit trail for compliance.

**Users:** Customer support agents (can process refunds, update accounts), customers (can only check their own orders), supervisors (can access all tools).  
**Tool requirements:** Check order status, process refunds, update account information, check inventory, create support tickets.

---

### 7.1. Tool Schema Design

**The challenge:** LLM needs clear instructions on when and how to use each tool. Schemas must be descriptive enough for the LLM to make good decisions, but not so verbose that they confuse it.

**Analysis:**
- Tools need to handle various user phrasings ("check my order", "where is my package", "order status")
- Parameters must be validated (order IDs have specific format)
- Some tools are idempotent (check order status), others are not (process refund needs idempotency key)

**Decision: Comprehensive schemas with clear descriptions and validation**

**Rationale:**
- Clear descriptions help LLM choose the right tool
- Parameter validation prevents errors before API calls
- Idempotency keys prevent duplicate refunds

**Example: Well-designed schema for `get_order_status`**

```json
{
  "name": "get_order_status",
  "description": "Retrieves the current status and shipping information for an order. Use this when the user asks about order status, shipping, delivery, tracking, or 'where is my order'. Always verify the user has access to this order before calling.",
  "parameters": {
    "type": "object",
    "properties": {
      "order_id": {
        "type": "string",
        "description": "The order identifier. Format: ORD- followed by 5 digits (e.g., 'ORD-12345'). This is required.",
        "pattern": "^ORD-[0-9]{5}$"
      },
      "include_tracking": {
        "type": "boolean",
        "description": "Whether to include tracking number and shipping details. Defaults to false. Set to true if user asks about tracking or shipping.",
        "default": false
      }
    },
    "required": ["order_id"]
  }
}
```

**Example: Well-designed schema for `process_refund` (with idempotency)**

```json
{
  "name": "process_refund",
  "description": "Processes a refund for an order. Use this ONLY when the user explicitly requests a refund. This action is irreversible. Requires idempotency_key to prevent duplicate refunds. Always confirm with the user before processing large refunds (>$500).",
  "parameters": {
    "type": "object",
    "properties": {
      "order_id": {
        "type": "string",
        "description": "The order identifier to refund. Format: ORD-XXXXX.",
        "pattern": "^ORD-[0-9]{5}$"
      },
      "amount": {
        "type": "number",
        "description": "Refund amount in dollars. Must be positive and cannot exceed order total. If not specified, refunds the full order amount.",
        "minimum": 0.01,
        "maximum": 10000
      },
      "reason": {
        "type": "string",
        "description": "Reason for refund (e.g., 'customer request', 'defective product', 'wrong item'). Required for compliance.",
        "enum": ["customer_request", "defective", "wrong_item", "late_delivery", "other"]
      },
      "idempotency_key": {
        "type": "string",
        "description": "Unique key to ensure idempotency. Generated automatically by the system. If the same key is used twice, returns the previous result without processing a duplicate refund.",
        "pattern": "^[a-f0-9]{32}$"
      }
    },
    "required": ["order_id", "reason", "idempotency_key"]
  }
}
```

**Trade-offs:**
- ✅ Clear descriptions help LLM make good decisions
- ✅ Validation prevents errors
- ⚠️ Verbose schemas increase token usage (slightly higher cost)
- ⚠️ More complex to maintain (but worth it for quality)

**Alternative considered:** Minimal schemas (just name and parameters) - rejected because LLM made more mistakes choosing tools and parameters.

### 7.2. Validation Strategy

**The challenge:** Need to validate tool calls at multiple layers to prevent errors, security issues, and ensure compliance.

**Analysis:**
- Schema validation catches format errors (wrong order ID format)
- Business logic validation catches logical errors (refund amount > order total)
- Permission validation prevents unauthorized access (user can't refund other people's orders)

**Decision: Multi-layer validation (schema → business logic → permissions)**

**Rationale:**
- Each layer catches different types of errors
- Fail fast (catch errors early, before expensive API calls)
- Security: Permission validation prevents unauthorized actions

**Implementation:**

```python
# Pseudocode
def validate_tool_call(tool_call, user):
    # Layer 1: Schema validation
    if not schema.validate(tool_call.parameters):
        return error("Invalid parameters: " + schema.get_errors())
    
    # Layer 2: Business logic validation
    if tool_call.tool_name == "process_refund":
        order = get_order(tool_call.parameters["order_id"])
        if tool_call.parameters["amount"] > order.total:
            return error("Refund amount cannot exceed order total")
        if order.status == "refunded":
            return error("Order already refunded")
    
    # Layer 3: Permission validation
    if not user.can_call_tool(tool_call.tool_name):
        return error("You don't have permission to call this tool")
    
    if tool_call.tool_name == "get_order_status":
        order = get_order(tool_call.parameters["order_id"])
        if order.user_id != user.id and not user.is_support_agent():
            return error("You can only check your own orders")
    
    return validated
```

**Trade-offs:**
- ✅ Catches errors early (before API calls)
- ✅ Multiple layers of security
- ⚠️ Adds latency (but minimal, ~10-20ms)
- ⚠️ More complex code (but necessary for production)

**Alternative considered:** Single validation layer (schema only) - rejected because it missed business logic and permission errors.

### 7.3. Idempotency Approach

**The challenge:** Refund processing must be idempotent. If a tool call fails and retries, or if a user clicks "submit" twice, we can't process duplicate refunds.

**Analysis:**
- Refunds are financial transactions (must be accurate)
- Network issues can cause duplicate requests
- Users might click "submit" multiple times

**Decision: Idempotency keys (UUID) generated per request**

**Rationale:**
- UUID ensures uniqueness (very low collision probability)
- System stores "already processed" state
- If same key used twice, return previous result (don't process again)

**Implementation:**

```python
# Pseudocode
def process_refund_with_idempotency(order_id, amount, reason, idempotency_key):
    # Check if already processed
    previous_result = get_refund_by_idempotency_key(idempotency_key)
    if previous_result:
        return previous_result  # Already processed, return previous result
    
    # Process refund
    refund = execute_refund(order_id, amount, reason)
    
    # Store idempotency key
    store_idempotency_key(idempotency_key, refund)
    
    return refund
```

**How idempotency key is generated:**
- Generated by system when user makes request (not by LLM)
- Passed to LLM as part of tool schema (LLM includes it in tool call)
- Stored with refund record

**Trade-offs:**
- ✅ Prevents duplicate refunds
- ✅ Safe to retry on failures
- ⚠️ Requires storage (idempotency key → result mapping)
- ⚠️ Storage must be fast (check before processing)

**Alternative considered:** Check-before-act (check if refund already exists) - rejected because race conditions could cause duplicate refunds if two requests arrive simultaneously.

### 7.4. Retry/Backoff Strategy

**The challenge:** External APIs (order system, payment processor) can fail temporarily. Need to retry intelligently without overwhelming services or causing duplicate actions.

**Analysis:**
- Order status API fails ~1% of the time (transient network errors)
- Refund API fails ~2% of the time (payment processor overload)
- Need to retry transient errors, but not permanent errors

**Decision: Exponential backoff with max 3 retries, jitter, and idempotency**

**Rationale:**
- 3 retries balances success rate vs latency (most transient errors resolve in 3 tries)
- Exponential backoff gives services time to recover
- Jitter prevents thundering herd (multiple requests retrying at same time)
- Idempotency ensures retries are safe (won't cause duplicate actions)

**Implementation:**

```python
# Pseudocode
def execute_tool_with_retry(tool_call, max_retries=3):
    for attempt in range(max_retries):
        try:
            result = execute_tool(tool_call)
            return result
        except TransientError as e:
            if attempt == max_retries - 1:
                return error("Service unavailable after 3 retries")
            
            # Exponential backoff with jitter
            base_delay = 2 ** attempt  # 1s, 2s, 4s
            jitter = random.uniform(0, 0.3) * base_delay  # Add randomness
            wait_time = base_delay + jitter
            sleep(wait_time)
        except PermanentError as e:
            return error("Cannot retry: " + str(e))
```

**Retry decision matrix:**

| Error Type | Retry? | Max Retries | Backoff |
|------------|--------|-------------|---------|
| Network timeout | Yes | 3 | Exponential |
| 5xx server error | Yes | 3 | Exponential |
| 429 rate limit | Yes | 2 | Exponential (longer) |
| 404 not found | No | 0 | N/A |
| 400 bad request | No | 0 | N/A |
| 401 unauthorized | No | 0 | N/A |

**Trade-offs:**
- ✅ Handles transient errors gracefully
- ✅ Jitter prevents thundering herd
- ⚠️ Adds latency (retries take time)
- ⚠️ More complex error handling

**Alternative considered:** No retries (fail immediately) - rejected because 1-2% failure rate was too high for production.

### 7.5. Security Controls (Allowlist, Auditing)

**The challenge:** Must prevent unauthorized tool access, log all actions for compliance, and prevent "confused deputy" attacks.

**Analysis:**
- Different users have different permissions (customers vs support agents vs supervisors)
- Compliance requires full audit trail (financial regulations)
- Security is non-negotiable (zero tolerance for breaches)

**Decision: Strict allowlist + user-specific permissions + comprehensive audit logging**

**Rationale:**
- Allowlist ensures only approved tools can be called
- User-specific permissions prevent privilege escalation
- Audit logging required for compliance and security

**Implementation:**

**1. Allowlist (tool-level):**

```python
# Pseudocode
ALLOWED_TOOLS = {
    "get_order_status": {"allowed_for": ["customer", "support_agent", "supervisor"]},
    "process_refund": {"allowed_for": ["support_agent", "supervisor"]},  # Customers cannot refund
    "update_account": {"allowed_for": ["customer", "support_agent"]},
    "check_inventory": {"allowed_for": ["support_agent", "supervisor"]},
    "create_support_ticket": {"allowed_for": ["customer", "support_agent"]},
}
```

**2. User permission validation:**

```python
# Pseudocode
def validate_user_permission(tool_name, user):
    if tool_name not in ALLOWED_TOOLS:
        return error("Tool not allowed")
    
    user_role = user.role
    if user_role not in ALLOWED_TOOLS[tool_name]["allowed_for"]:
        return error("You don't have permission to call this tool")
    
    return validated
```

**3. Resource-level permission (prevent confused deputy):**

```python
# Pseudocode
def validate_resource_access(tool_call, user):
    if tool_call.tool_name == "get_order_status":
        order = get_order(tool_call.parameters["order_id"])
        # Customers can only access their own orders
        if user.role == "customer" and order.user_id != user.id:
            return error("You can only check your own orders")
    
    if tool_call.tool_name == "process_refund":
        order = get_order(tool_call.parameters["order_id"])
        # Support agents can refund any order, but log it
        if user.role == "support_agent":
            log_audit_event("support_agent_refund", user.id, order.id)
    
    return validated
```

**4. Audit logging:**

```python
# Pseudocode
def log_tool_call(tool_call, user, result, execution_time):
    audit_log.write({
        "timestamp": now(),
        "request_id": get_request_id(),
        "user_id": user.id,
        "user_role": user.role,
        "tool_name": tool_call.tool_name,
        "parameters": sanitize_parameters(tool_call.parameters),  # Remove sensitive data
        "result": "success" if result.success else "failure",
        "error_message": result.error if not result.success else None,
        "execution_time_ms": execution_time,
        "ip_address": user.ip_address
    })
```

**Trade-offs:**
- ✅ Comprehensive security (multiple layers)
- ✅ Full audit trail for compliance
- ⚠️ More complex permission logic
- ⚠️ Audit logs require storage (but necessary)

**Alternative considered:** Simple allowlist only (no user-specific permissions) - rejected because customers shouldn't be able to call admin tools.

### 7.6. Observability Setup

**The challenge:** Need to monitor tool calls for performance, errors, and compliance. Must trace end-to-end requests.

**Analysis:**
- Multiple tool calls per user request (need to trace full flow)
- Performance matters (<5s response time)
- Need to identify bottlenecks and errors

**Decision: Request ID tracing + comprehensive metrics + structured logging**

**Rationale:**
- Request ID connects all tool calls to user request (end-to-end trace)
- Metrics help identify performance issues and errors
- Structured logs enable searching and analysis

**Implementation:**

**1. Request ID (correlation ID):**

```python
# Pseudocode
def handle_user_request(user_query, user):
    request_id = generate_request_id()  # e.g., "req_abc123"
    
    # All tool calls use this request_id
    result = execute_tool_calls(user_query, user, request_id)
    
    return result
```

**2. Metrics tracked:**

- Tool call success rate (per tool)
- Tool call latency (P50, P95, P99 per tool)
- Error rate by error type
- Tool call volume (calls per minute)
- Cost per tool call

**3. Structured logging:**

```json
{
  "request_id": "req_abc123",
  "timestamp": "2024-01-15T10:30:00.100Z",
  "tool_name": "get_order_status",
  "parameters": {"order_id": "ORD-12345"},
  "execution_time_ms": 245,
  "result": "success",
  "user_id": "user_456"
}
```

**Trade-offs:**
- ✅ Full observability (can debug any issue)
- ✅ Performance monitoring (identify bottlenecks)
- ⚠️ Logging overhead (but minimal, ~1-2ms per call)
- ⚠️ Storage costs (but necessary for production)

**Alternative considered:** Minimal logging (errors only) - rejected because need full audit trail for compliance.

### 7.7. End-to-End Flow Example

**User:** Sarah (customer)  
**Query:** "Check the status of order ORD-12345 and if it hasn't shipped, I want a refund"

**Step 1: Request received**
- System generates request ID: `req_abc123`
- User authenticated: `user_id: user_456`, `role: customer`

**Step 2: LLM receives tool list and query**
- Available tools: `get_order_status`, `process_refund` (but customer can only check status, not process refunds directly)
- LLM analyzes: "User wants to check order status, then potentially request refund"

**Step 3: First tool call - `get_order_status`**
- LLM generates: `{tool: "get_order_status", parameters: {order_id: "ORD-12345", include_tracking: true}}`
- Validation:
  - ✅ Tool in allowlist
  - ✅ User has permission (customers can check orders)
  - ✅ Parameters valid (order_id format correct)
  - ✅ Resource access: Order belongs to user_456 ✅
- Execution: `get_order_status(ORDER-12345)` → Returns `{status: "pending", shipped: false, tracking: null}`
- Logged: `request_id: req_abc123, tool: get_order_status, execution_time: 245ms, result: success`

**Step 4: LLM receives result and decides next action**
- LLM sees: Order hasn't shipped (status: "pending")
- LLM decides: User wants refund, but customer cannot process refunds directly. LLM should inform user and offer to create support ticket or escalate.

**Step 5: LLM generates response (no second tool call)**
- LLM: "I checked order ORD-12345 and it hasn't shipped yet (status: pending). I can't process refunds directly, but I can create a support ticket for you. Would you like me to do that?"
- User: "Yes, please create a ticket"

**Step 6: Second tool call - `create_support_ticket`**
- LLM generates: `{tool: "create_support_ticket", parameters: {order_id: "ORD-12345", issue_type: "refund_request", description: "Customer requested refund for unshipped order"}}`
- Validation: ✅ All checks pass
- Execution: Creates ticket → Returns `{ticket_id: "TKT-789", status: "created"}`
- Logged: `request_id: req_abc123, tool: create_support_ticket, execution_time: 180ms, result: success`

**Step 7: Final response**
- LLM: "I've created support ticket TKT-789 for your refund request. A support agent will review it and process your refund within 24 hours."

**Step 8: Audit log entry**
```json
{
  "request_id": "req_abc123",
  "user_id": "user_456",
  "user_role": "customer",
  "query": "Check order ORD-12345 and refund if not shipped",
  "tool_calls": [
    {
      "tool": "get_order_status",
      "parameters": {"order_id": "ORD-12345"},
      "result": "success",
      "execution_time_ms": 245
    },
    {
      "tool": "create_support_ticket",
      "parameters": {"order_id": "ORD-12345", "issue_type": "refund_request"},
      "result": "success",
      "execution_time_ms": 180
    }
  ],
  "total_execution_time_ms": 425,
  "timestamp": "2024-01-15T10:30:00.525Z"
}
```

---

## 8. TRADE-OFFS AND DECISIONS (Mini ADR)

This section covers key architectural decisions you'll face when implementing tool calling.

### 8.1. Decision: Synchronous vs Asynchronous Tool Execution

**The challenge:** Should tool calls execute synchronously (wait for result before continuing) or asynchronously (fire and forget, or poll for result)?

**Synchronous execution:**
- **How it works:** LLM calls tool, waits for result, then continues
- **Pros:** Simple, LLM can use result immediately, easier to debug
- **Cons:** Slower (waits for each tool), blocks if tool is slow
- **When to use:** Most tool calls (order status, simple updates), MVP phase

**Asynchronous execution:**
- **How it works:** LLM calls tool, continues immediately, result comes later (webhook or polling)
- **Pros:** Faster (doesn't wait), can handle long-running operations
- **Cons:** More complex (need to handle async results), LLM can't use result immediately
- **When to use:** Long-running operations (generate report, process large batch), production at scale

**Decision framework:**

```
Is the tool call expected to take >5 seconds?
│
├─ NO → Use synchronous ✅
│  (Most tool calls: order status, refunds, updates)
│
└─ YES → Consider asynchronous
   │
   ├─ Can user wait? → Use synchronous with progress updates
   │
   └─ User needs immediate response? → Use asynchronous
      (e.g., "I've started processing your refund, you'll get an email when it's done")
```

**Recommendation:** Start with synchronous for MVP, move to asynchronous for long-running operations in production.

### 8.2. Decision: Tool Allowlist vs Dynamic Tool Discovery

**The challenge:** Should tools be statically defined (allowlist) or dynamically discovered (LLM finds tools at runtime)?

**Allowlist (static):**
- **How it works:** Tools are predefined in code/config, LLM can only call these
- **Pros:** Secure (only approved tools), predictable, easier to audit
- **Cons:** Less flexible (need code change to add tool), more maintenance
- **When to use:** Production systems, security-critical use cases, MVP

**Dynamic discovery:**
- **How it works:** LLM searches for available tools at runtime (e.g., API discovery, plugin system)
- **Pros:** Flexible (add tools without code changes), scalable
- **Cons:** Security risk (LLM might find and call unauthorized tools), unpredictable
- **When to use:** Research/prototype phase, internal tools with low security risk

**Decision framework:**

```
Is security a concern?
│
├─ YES → Use allowlist ✅
│  (Production, customer-facing, financial/medical)
│
└─ NO → Consider dynamic discovery
   │
   ├─ Internal tool only? → Maybe dynamic discovery
   │
   └─ External/customer-facing? → Use allowlist
```

**Recommendation:** Always use allowlist for production. Dynamic discovery is too risky for enterprise use cases.

### 8.3. Decision: Retry Strategy (When/How Many Times)

**The challenge:** How many times should you retry a failed tool call? When should you retry vs fail immediately?

**Factors to consider:**

1. **Error type:**
   - Transient errors (network timeout, 5xx) → Retry
   - Permanent errors (404, 400) → Don't retry

2. **Tool criticality:**
   - Critical tools (process refund) → More retries (3-5)
   - Non-critical tools (check inventory) → Fewer retries (1-2)

3. **User experience:**
   - User waiting? → Fewer retries, fail fast
   - Background job? → More retries, can wait longer

**Decision framework:**

```
What type of error?
│
├─ Transient (5xx, timeout) → Retry
│  │
│  ├─ Critical tool? → 3-5 retries with exponential backoff
│  │
│  └─ Non-critical? → 2-3 retries
│
└─ Permanent (4xx) → Don't retry
   Return error to user immediately
```

**Recommendation:**
- **MVP:** 2-3 retries for all transient errors
- **Production:** 3-5 retries for critical tools, 2-3 for non-critical, with jitter

### 8.4. Decision: Human-in-the-Loop (HITL) for Critical Actions

**The challenge:** Should critical actions (refunds, account changes, deletions) require human approval, or can the AI act autonomously?

**Autonomous (no HITL):**
- **How it works:** AI processes actions immediately without human review
- **Pros:** Fast, scalable, good user experience
- **Cons:** Risk of errors, no human oversight
- **When to use:** Low-risk actions (check status, read operations), well-tested systems

**Human-in-the-Loop (HITL):**
- **How it works:** AI proposes action, human approves before execution
- **Pros:** Safer, human oversight, catches errors
- **Cons:** Slower, requires human availability, less scalable
- **When to use:** High-risk actions (refunds >$X, account deletions, financial transactions)

**Decision framework:**

```
What is the risk if this action is wrong?
│
├─ Low risk (read-only, small amounts) → Autonomous ✅
│  (Check order status, update email, small refunds <$50)
│
├─ Medium risk (moderate amounts, reversible) → Conditional HITL
│  (Refunds $50-$500: Autonomous if conditions met, HITL otherwise)
│
└─ High risk (large amounts, irreversible) → Always HITL ✅
   (Refunds >$500, account deletion, financial transfers)
```

**Recommendation:**
- **MVP:** HITL for all critical actions (safer, builds trust)
- **Production:** Conditional HITL (autonomous for low-risk, HITL for high-risk)

**Example: Conditional HITL**

```python
# Pseudocode
def process_refund(order_id, amount, user):
    if amount > 500:  # High-risk threshold
        return request_human_approval(order_id, amount, user)
    
    if amount > 50 and user.is_new_customer():  # Medium-risk
        return request_human_approval(order_id, amount, user)
    
    # Low-risk: process autonomously
    return execute_refund(order_id, amount)
```

---

## NEXT STEPS

**Recommended reading:**
- [`2.1_rag.md`](./2.1_rag.md) — Combining RAG with tool calling for comprehensive solutions
- [`agentic_ai.md`](./agentic_ai.md) — Tool calling in agentic systems with budget management and stopping criteria
- [`guardrails.md`](./guardrails.md) — Security controls and input validation for tool calls
- [`evals.md`](./evals.md) — Measuring tool calling quality and success rates
- [`observability_llmops.md`](./observability_llmops.md) — Observing and tracing tool calls end-to-end
- [`../06-risk-governance-ethics/data_privacy_and_security.md`](../06-risk-governance-ethics/data_privacy_and_security.md) — IAM, audit logging, and compliance for tool calling

---

